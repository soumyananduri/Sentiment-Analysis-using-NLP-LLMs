{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e387cefc-b983-4501-be06-e67c20ea7438",
   "metadata": {},
   "source": [
    "## Question 3 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6360c-9f60-4dd5-9ca1-0c3dc3da8008",
   "metadata": {},
   "source": [
    "**(i)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853387e1-03ea-498e-9078-3165bc6f17ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from skimage.color import rgb2hed\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Load dataset\n",
    "CSV_PATH = \"/Users/soumya/Downloads/protein_expression_data.csv\"  # CSV file containing image filenames & CD11b expression\n",
    "IMAGE_FOLDER = \"/Users/soumya/Desktop/patches_256/\"  # Adjust if necessary\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "def format_image_filename(filename, id_value):\n",
    "    specimen = filename.split('-')[-1]  # Extract last part after hyphen\n",
    "    formatted_filename = f\"{specimen}_{id_value}.png\"\n",
    "    return os.path.join(IMAGE_FOLDER, formatted_filename)\n",
    "\n",
    "df[\"image_path\"] = df.apply(lambda row: format_image_filename(row[\"VisSpot\"], row[\"id\"]), axis=1)\n",
    "\n",
    "# Normalize CD11b values\n",
    "mean_cd11b = df[\"CD11b\"].mean()\n",
    "std_cd11b = df[\"CD11b\"].std()\n",
    "df[\"CD11b\"] = (df[\"CD11b\"] - mean_cd11b) / std_cd11b\n",
    "\n",
    "# Split dataset (Train: B1, C1, D1 | Test: A1)\n",
    "df[\"Specimen\"] = df[\"VisSpot\"].apply(lambda x: x.split('-')[-1])\n",
    "test_set = df[df[\"Specimen\"] == \"A1\"].reset_index(drop=True)\n",
    "train_set = df[df[\"Specimen\"].isin([\"B1\", \"C1\", \"D1\"])].reset_index(drop=True)\n",
    "\n",
    "# Image Transformations with Data Augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Custom Dataset Class\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.df.iloc[idx][\"CD11b\"], dtype=torch.float32)\n",
    "        return image, label\n",
    "\n",
    "# Creating Data Loaders\n",
    "train_dataset = ProteinDataset(train_set, transform=transform)\n",
    "test_dataset = ProteinDataset(test_set, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Define Neural Network Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        for param in list(self.base_model.parameters())[:-10]:  # Freeze all but last 10 layers initially\n",
    "            param.requires_grad = False\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Tanh()  # Ensure output is in the normalized range\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x).squeeze()\n",
    "\n",
    "# Initialize Model\n",
    "model = CNNModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)  # Lower learning rate for stable training\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0001, steps_per_epoch=len(train_loader), epochs=20)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 20\n",
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "        epoch_loss += loss.item()\n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluate Model\n",
    "model.eval()\n",
    "predictions, true_values = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        predictions.extend(outputs.numpy())\n",
    "        true_values.extend(labels.numpy())\n",
    "\n",
    "# Compute Performance Metrics\n",
    "rmse = np.sqrt(mean_squared_error(true_values, predictions))\n",
    "pearson_corr, _ = pearsonr(true_values, predictions)\n",
    "spearman_corr, _ = spearmanr(true_values, predictions)\n",
    "r2 = r2_score(true_values, predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr:.4f}\")\n",
    "print(f\"Spearman Correlation: {spearman_corr:.4f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.plot(train_losses, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: True vs Predicted\n",
    "plt.scatter(true_values, predictions, alpha=0.5)\n",
    "plt.xlabel(\"True CD11b Expression\")\n",
    "plt.ylabel(\"Predicted CD11b Expression\")\n",
    "plt.title(\"True vs Predicted CD11b Expression\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec549d7-76be-4bab-9608-8ff95dc72c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68549946-faf3-4171-9efa-83a0575ede85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e6114-191c-44ae-ba47-6f94513eadcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Columns: Index(['Unnamed: 0', 'VisSpot', 'Location_Center_Y', 'Location_Center_X',\n",
      "       'SMAa', 'CD11b', 'CD44', 'CD31', 'CDK4', 'YKL40', 'CD11c', 'HIF1a',\n",
      "       'CD24', 'TMEM119', 'OLIG2', 'GFAP', 'VISTA', 'IBA1', 'CD206', 'PTEN',\n",
      "       'NESTIN', 'TCIRG1', 'CD74', 'MET', 'P2RY12', 'CD163', 'S100B', 'cMYC',\n",
      "       'pERK', 'EGFR', 'SOX2', 'HLADR', 'PDGFRa', 'MCT4', 'DNA1', 'DNA3',\n",
      "       'MHCI', 'CD68', 'CD14', 'KI67', 'CD16', 'SOX10', 'id'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0                VisSpot  Location_Center_Y  Location_Center_X  \\\n",
      "0           0  AAACAAGTATCTCCCA-1-A1         142.183168         945.889802   \n",
      "1           1  AAACAAGTATCTCCCA-1-C1         625.877370         306.087125   \n",
      "2           2  AAACAATCTACTAGCA-1-A1         604.854953         104.873577   \n",
      "3           3  AAACAATCTACTAGCA-1-C1         423.898653         493.267222   \n",
      "4           4  AAACACCAATAACTGC-1-A1          14.059328         192.251135   \n",
      "\n",
      "       SMAa     CD11b      CD44      CD31      CDK4     YKL40  ...      MCT4  \\\n",
      "0 -2.895476  0.635913 -1.799958 -3.456108 -1.097289 -0.135151  ... -0.266500   \n",
      "1 -2.829915 -1.523621 -2.198967 -3.407043 -1.313483 -0.137963  ... -0.047092   \n",
      "2 -2.895476 -2.647804 -1.919671 -3.456108  0.708968 -0.417891  ...  0.205904   \n",
      "3 -2.621611 -3.378916 -2.198967 -3.407043 -0.212488  0.005946  ... -0.394214   \n",
      "4 -2.434658 -1.288683 -1.628401 -2.556167 -0.763331 -0.269121  ... -0.134511   \n",
      "\n",
      "       DNA1      DNA3      MHCI      CD68      CD14      KI67      CD16  \\\n",
      "0  0.396454  0.394441 -0.715414 -2.760720 -2.032137 -3.156091 -1.131006   \n",
      "1  0.209803  0.155667 -0.157574 -1.638258 -2.740175 -3.096359 -0.518767   \n",
      "2  0.062106  0.059508  0.185727 -1.071069 -1.146924 -1.550763 -0.398849   \n",
      "3 -0.725604 -0.723764 -0.026163 -1.695244 -1.386114 -3.096359 -1.912111   \n",
      "4  0.426636  0.428499 -0.032983 -1.030893 -2.039006 -2.361533 -1.638938   \n",
      "\n",
      "      SOX10      id  \n",
      "0 -0.155221  50x102  \n",
      "1 -3.421210  50x102  \n",
      "2  0.497964    3x43  \n",
      "3 -3.421210    3x43  \n",
      "4 -0.099874   59x19  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "Unique Specimens Found: ['A1' 'C1' 'B1' 'D1']\n",
      "Number of rows after filtering: 9921\n",
      "Number of Unique Specimens: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from skimage.color import rgb2hed\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Load dataset\n",
    "CSV_PATH = \"/Users/soumya/Downloads/protein_expression_data.csv\"\n",
    "IMAGE_FOLDER = \"/Users/soumya/Desktop/patches_256/\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Display dataset columns to debug\n",
    "print(\"Dataset Columns:\", df.columns)\n",
    "print(df.head())\n",
    "\n",
    "# Ensure 'VisSpot' column exists\n",
    "if \"VisSpot\" not in df.columns:\n",
    "    raise ValueError(\"Column 'VisSpot' is missing in the dataset. Check CSV structure.\")\n",
    "\n",
    "# Extract specimen correctly\n",
    "df[\"Specimen\"] = df[\"VisSpot\"].apply(lambda x: x.split('-')[-1] if '-' in x else \"Unknown\")\n",
    "\n",
    "# Keep only valid specimens ('A1', 'B1', 'C1', 'D1')\n",
    "df = df[df[\"Specimen\"].isin([\"A1\", \"B1\", \"C1\", \"D1\"])].reset_index(drop=True)\n",
    "\n",
    "# Display unique specimens and row count\n",
    "print(\"Unique Specimens Found:\", df[\"Specimen\"].unique())\n",
    "print(f\"Number of rows after filtering: {len(df)}\")\n",
    "\n",
    "# Ensure protein expression columns are numeric\n",
    "protein_columns = df.columns.difference([\"Unnamed: 0\", \"VisSpot\", \"Specimen\", \"id\", \"Location_Center_Y\", \"Location_Center_X\"])\n",
    "for col in protein_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop NaN values\n",
    "df = df.dropna(subset=protein_columns).reset_index(drop=True)\n",
    "\n",
    "# Normalize protein expression values (Min-Max Scaling)\n",
    "for protein in protein_columns:\n",
    "    min_val, max_val = df[protein].min(), df[protein].max()\n",
    "    df[protein] = (df[protein] - min_val) / (max_val - min_val) if min_val != max_val else 0\n",
    "\n",
    "# Check unique specimens count for GroupKFold\n",
    "num_unique_specimens = df[\"Specimen\"].nunique()\n",
    "print(f\"Number of Unique Specimens: {num_unique_specimens}\")\n",
    "if num_unique_specimens < 2:\n",
    "    raise ValueError(f\"Not enough unique specimens for GroupKFold. Found {num_unique_specimens} specimens.\")\n",
    "\n",
    "# Generate correct image filenames\n",
    "def format_image_filename(filename, id_value):\n",
    "    specimen = filename.split('-')[-1]\n",
    "    return os.path.join(IMAGE_FOLDER, f\"{specimen}_{id_value}.png\")\n",
    "\n",
    "df[\"image_path\"] = df.apply(lambda row: format_image_filename(row[\"VisSpot\"], row[\"id\"]), axis=1)\n",
    "\n",
    "# Image Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom Dataset\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, df, protein_columns, transform=None):\n",
    "        self.df = df\n",
    "        self.protein_columns = protein_columns\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx][\"image_path\"]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Ensure correct label format\n",
    "        labels = self.df.iloc[idx][self.protein_columns].values.astype(np.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        return image, labels\n",
    "\n",
    "# Define CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.base_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False  # Freeze feature extractor\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(self.base_model.fc.in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Cross-validation with GroupKFold\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gkf = GroupKFold(n_splits=4)\n",
    "groups = df[\"Specimen\"]\n",
    "\n",
    "metrics_results = {protein: {\"RMSE\": [], \"Pearson\": [], \"Spearman\": [], \"R2\": []} for protein in protein_columns}\n",
    "\n",
    "for train_idx, test_idx in gkf.split(df, groups=groups):\n",
    "    train_df, test_df = df.iloc[train_idx], df.iloc[test_idx]\n",
    "    \n",
    "    train_dataset = ProteinDataset(train_df, protein_columns, transform=transform)\n",
    "    test_dataset = ProteinDataset(test_df, protein_columns, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize Model\n",
    "    model = CNNModel(num_outputs=len(protein_columns)).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "    \n",
    "    # Train Model\n",
    "    for epoch in range(10):  # 10 epochs for each fold\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate Model\n",
    "    model.eval()\n",
    "    predictions, true_values = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "            true_values.append(labels.cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_values = np.concatenate(true_values, axis=0)\n",
    "\n",
    "    for i, protein in enumerate(protein_columns):\n",
    "        rmse = np.sqrt(mean_squared_error(true_values[:, i], predictions[:, i]))\n",
    "        pearson_corr, _ = pearsonr(true_values[:, i], predictions[:, i])\n",
    "        spearman_corr, _ = spearmanr(true_values[:, i], predictions[:, i])\n",
    "        r2 = r2_score(true_values[:, i], predictions[:, i])\n",
    "\n",
    "        metrics_results[protein][\"RMSE\"].append(rmse)\n",
    "        metrics_results[protein][\"Pearson\"].append(pearson_corr)\n",
    "        metrics_results[protein][\"Spearman\"].append(spearman_corr)\n",
    "        metrics_results[protein][\"R2\"].append(r2)\n",
    "\n",
    "# Compute Averages\n",
    "df_metrics = pd.DataFrame({protein: {metric: np.mean(values) for metric, values in results.items()} for protein, results in metrics_results.items()}).T\n",
    "num_high_spearman = sum(df_metrics[\"Spearman\"] > 0.7)\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(df_metrics)\n",
    "print(f\"Number of proteins with Spearman > 0.7: {num_high_spearman}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4fb7ea-477f-4577-b079-f331a703d445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59447068-10fe-46c1-9e30-8341388ea573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
